{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d593010",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2ed54",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae68c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = {\n",
    "    \"root\": \"../\",\n",
    "    \"seeds\": 123,\n",
    "    \"batch_size\": 16,\n",
    "    \"class_a_index\": 5, # 5 -> dog\n",
    "    \"class_b_index\": 3, # 3 -> cat\n",
    "    \"class_a_size\": None, # Use None to read all class_a samples (5000 rows)\n",
    "    \"class_b_size\": None,\n",
    "    \"epoch\": 400,\n",
    "    \"download_cifar10\": False, # set to True if you have not downloaded cifar10 dataset \n",
    "}\n",
    "config = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e823cd0",
   "metadata": {},
   "source": [
    "## Reprodicibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_seed(config.seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb955a4a",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader:\n",
    "    \n",
    "    def __init__(self, class_a_size=None, class_b_size=None, seeds=123, download=True):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            class_a_size: The number of samples for class a (e.g. dog).\n",
    "            class_b_size: The number of samples for class b (e.g. cat).\n",
    "        \"\"\"\n",
    "        self.class_a_size = class_a_size # e.g. 5000\n",
    "        self.class_b_size = class_b_size # e.g. 5000\n",
    "        self.seeds = seeds\n",
    "        self.classes = ['plane', 'car', 'bird', 'cat',\n",
    "                   'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        self.download = download\n",
    "        \n",
    "    def sampling(self, indices, num, seeds=123):\n",
    "        \"\"\"\n",
    "        Sample num samples from indices randomly. If num is a float and 0.0 <= num <= 1.0,\n",
    "        we sample num percentage of samples from indices.\n",
    "        \"\"\"\n",
    "        np.random.seed(self.seeds)\n",
    "        if isinstance(num, float) and 0 <= num <= 1:\n",
    "            size = int(num * len(indices))\n",
    "            samples = np.random.choice(indices, size)\n",
    "        elif isinstance(num, int) and num <= len(indices):\n",
    "            size = num\n",
    "            samples = np.random.choice(indices, size)\n",
    "        elif num is None:\n",
    "            samples = indices\n",
    "        else:\n",
    "            print(\"Please make sure 'num' is in the correct range\")\n",
    "        return samples       \n",
    "        \n",
    "    def get_subset_index(self, labels, targets):\n",
    "        \n",
    "        # get subsets\n",
    "        sample_indices = []\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] in targets:\n",
    "                sample_indices.append(i)\n",
    "            \n",
    "        return sample_indices\n",
    "\n",
    "    def load_dataset(self, data_dir, batch_size, train_a_label=5, train_b_label=3):\n",
    "        \n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        \n",
    "        # 1. read train data belonged to train_labels\n",
    "        trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                                download=self.download, transform=transform)\n",
    "        \n",
    "        # 1-1. get index belonged to class a and b with sampling\n",
    "        class_a_indices = self.get_subset_index(trainset.targets, [train_a_label])\n",
    "        class_a_indices = self.sampling(class_a_indices, self.class_a_size, self.seeds)\n",
    "        \n",
    "        class_b_indices = self.get_subset_index(trainset.targets, [train_b_label])\n",
    "        class_b_indices = self.sampling(class_b_indices, self.class_b_size, self.seeds)\n",
    "        \n",
    "        train_index_subset = np.concatenate((class_a_indices, class_b_indices))\n",
    "        trainsubset = torch.utils.data.Subset(trainset, train_index_subset)\n",
    "\n",
    "        # 1. read test data and separate them into (dog, cat) and (the other 8)\n",
    "        testset = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                               download=self.download, transform=transform)\n",
    "        test_index_class_ab = self.get_subset_index(\n",
    "            labels=testset.targets,\n",
    "            targets=[train_a_label, train_b_label]\n",
    "        )\n",
    "        test_index_others = self.get_subset_index(\n",
    "            labels=testset.targets,\n",
    "            targets=[cls for cls in range(len(self.classes)) if cls not in [train_a_label, train_b_label]]\n",
    "        )\n",
    "        testsubset_ab = torch.utils.data.Subset(testset, test_index_class_ab)\n",
    "        testsubset_others = torch.utils.data.Subset(testset, test_index_others)\n",
    "\n",
    "        return trainsubset, (testsubset_ab, testsubset_others)\n",
    "\n",
    "    def generate_loader(self, dataset, batch_size, shuffle=True, drop_last=True):\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataloader = CustomDataLoader(\n",
    "    class_a_size=config.class_a_size,\n",
    "    class_b_size=config.class_b_size,\n",
    "    seeds=config.seeds,\n",
    "    download=config.download_cifar10)\n",
    "\n",
    "trainset, (testset_ab, testset_others) = mydataloader.load_dataset(\n",
    "    data_dir=os.path.join(config.root, \"data\"),\n",
    "    batch_size=config.batch_size,\n",
    "    train_a_label=config.class_a_index, # dog\n",
    "    train_b_label=config.class_b_index, # cat\n",
    ")\n",
    "\n",
    "train_loader = mydataloader.generate_loader(\n",
    "    dataset=trainset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_ab_loader = mydataloader.generate_loader(\n",
    "    dataset=testset_ab,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_others_loader = mydataloader.generate_loader(\n",
    "    dataset=testset_others,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2089d73",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390087e",
   "metadata": {},
   "source": [
    "### CNN Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBased(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(CNNBased, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44e39a",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63cc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158b78f",
   "metadata": {},
   "source": [
    "## Train Test Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da07b61",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, criterion, optimizer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4100de",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e761ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(testloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee571a8",
   "metadata": {},
   "source": [
    "### Utils\n",
    "\n",
    "- Save anything for plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ba5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16670fff",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6bfd2",
   "metadata": {},
   "source": [
    "### Reload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1c7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628a0134",
   "metadata": {},
   "source": [
    "### Training Requirements\n",
    "\n",
    "- optimizer\n",
    "- criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb5583",
   "metadata": {},
   "source": [
    "### Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345337f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
